{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,cross_val_predict,StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,log_loss,make_scorer\n",
    "from sklearn.multiclass import OneVsOneClassifier,OneVsRestClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(r'C:\\Users\\Rahul\\Desktop\\MachineHack-metalfurnace-classification\\Train.csv')\n",
    "test=pd.read_csv(r'C:\\Users\\Rahul\\Desktop\\MachineHack-metalfurnace-classification\\Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.848564</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>1.305455</td>\n",
       "      <td>2.329398</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>-1.080663</td>\n",
       "      <td>0.443257</td>\n",
       "      <td>-0.406121</td>\n",
       "      <td>-0.687687</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>3.727218</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.825098</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>3.032397</td>\n",
       "      <td>-2.442599</td>\n",
       "      <td>1.305455</td>\n",
       "      <td>-0.276144</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>-1.080663</td>\n",
       "      <td>-0.232546</td>\n",
       "      <td>-0.406366</td>\n",
       "      <td>-0.687687</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.848564</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>1.305455</td>\n",
       "      <td>2.329398</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>0.925358</td>\n",
       "      <td>1.459782</td>\n",
       "      <td>1.221876</td>\n",
       "      <td>1.877777</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511733</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>-0.525726</td>\n",
       "      <td>-0.276144</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>0.925358</td>\n",
       "      <td>-0.008030</td>\n",
       "      <td>-0.406366</td>\n",
       "      <td>1.504523</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.825098</td>\n",
       "      <td>-0.26425</td>\n",
       "      <td>-0.461423</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>-0.525726</td>\n",
       "      <td>-0.276144</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.090167</td>\n",
       "      <td>0.107958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.233285</td>\n",
       "      <td>0.925358</td>\n",
       "      <td>-0.573268</td>\n",
       "      <td>-1.164793</td>\n",
       "      <td>1.877777</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>-0.232472</td>\n",
       "      <td>0.102129</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f0       f1        f2        f3        f4        f5        f6  \\\n",
       "0  1.848564 -0.26425 -0.461423  0.409400  1.305455  2.329398  0.370965   \n",
       "1 -0.825098 -0.26425  3.032397 -2.442599  1.305455 -0.276144  0.370965   \n",
       "2  1.848564 -0.26425 -0.461423  0.409400  1.305455  2.329398  0.370965   \n",
       "3  0.511733 -0.26425 -0.461423  0.409400 -0.525726 -0.276144  0.370965   \n",
       "4 -0.825098 -0.26425 -0.461423  0.409400 -0.525726 -0.276144  0.370965   \n",
       "\n",
       "         f7        f8   f9  ...       f19       f20       f21       f22  \\\n",
       "0  0.090167  0.107958  0.0  ...  0.085505  0.233285 -1.080663  0.443257   \n",
       "1  0.090167  0.107958  0.0  ...  0.085505  0.233285 -1.080663 -0.232546   \n",
       "2  0.090167  0.107958  0.0  ...  0.085505  0.233285  0.925358  1.459782   \n",
       "3  0.090167  0.107958  0.0  ...  0.085505  0.233285  0.925358 -0.008030   \n",
       "4  0.090167  0.107958  0.0  ...  0.085505  0.233285  0.925358 -0.573268   \n",
       "\n",
       "        f23       f24       f25       f26       f27  grade  \n",
       "0 -0.406121 -0.687687  0.271886  3.727218  0.102129      2  \n",
       "1 -0.406366 -0.687687  0.271886 -0.232472  0.102129      4  \n",
       "2  1.221876  1.877777  0.271886 -0.232472  0.102129      2  \n",
       "3 -0.406366  1.504523  0.271886 -0.232472  0.102129      2  \n",
       "4 -1.164793  1.877777  0.271886 -0.232472  0.102129      2  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f7,f8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.107958     612\n",
      "-6.585461       6\n",
      "-13.278881      2\n",
      "Name: f8, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x233126b44a8>"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABaEAAAGfCAYAAABGAR6dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAG7hJREFUeJzt3X+w5Xdd3/HXu7sL3FpxkUDTbNgGBlhFwQSPFGqrEiIbWyoRpQNTRsY63RkHO9qpscRMf9iBobodqR0da0Zo1bFSBpLAFOtKkP6cAbzboCHC1khRsqtmGVj6g20Iy6d/3LPhst67uzd33/f8uI/HTGbv+Z5zz/d97t7PuWef+d7vqTFGAAAAAACgw5+Z9QAAAAAAACwvERoAAAAAgDYiNAAAAAAAbURoAAAAAADaiNAAAAAAALQRoQEAAAAAaCNCAwAAAADQRoQGAAAAAKCNCA0AAAAAQJu9sx5gvauuumpcd911sx4DAAAAAICLOH78+KfGGE+5nNvOVYS+7rrrsrq6OusxAAAAAAC4iKr6g8u9rdNxAAAAAADQRoQGAAAAAKCNCA0AAAAAQBsRGgAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG32znoAkrvvPZmjx07k5Jmz2VOVc2Ps+J/7V/alKvnM5x6Z2QzLNOsizLhIsy7CjIs06yLMuEizbmfGA/tX8uKveUre/7HTO/IzYCe/ngf2r+TWw4dyyw0HtvRzbhH+zndy1u1+j/h67r4ZF2nWRZhxkWadhxkv9zlrHmb19dx9X89lmnURZtzts271NdwyrfdFmvVK/52f//cPG6sxxqxneNRkMhmrq6uzHmNH3X3vydx25305+8i5WY8CAFfUyr49+e5vPJB3Hj/p5xwAALDUVvbtyZte8dxdFaKr6vgYY3I5t20/HUdV3VxVJ6rqgap6fff+Fs3RYyf8wxyApXT2kXP51Q9+0s85AABg6Z195FyOHjsx6zHmVmuErqo9SX42yXckeU6SV1fVczr3uWhOnTk76xEAoM25OfqNKwAAgE463+a6j4R+QZIHxhgfH2N8Psnbkry8eZ8L5Zr9K7MeAQDa7Kma9QgAAAA7QufbXHeEPpDkk+suPzjdxtSthw9lZd+eWY8BAFfcyr49efVfepqfcwAAwNJb2bcntx4+NOsx5lZ3hN7o8Kcv+73cqjpSVatVtXr69OnmcebPLTccyJte8dwcmP6fkvNHjO30n/tX9uVJf3bfTGdYplkXYcZFmnURZlykWRdhxkWadTszHti/kte88OCO/QzYya/ngf0redMrnps33PLcLf2cW4S/852cdbvfI76eu2/GRZp1EWZcpFnnYcbLfc6ah1l9PXff13OZZl2EGXf7rFt9DbdM632RZr3Sf+e77U0Jt6pG47kaq+pFSf7JGOPw9PJtSTLGeNNGt59MJmN1dbVtHgAAAAAAtq+qjo8xJpdz2+4joX8rybOq6ulV9bgkr0ry7uZ9AgAAAAAwJ/Z23vkY4wtV9YNJjiXZk+StY4z7O/cJAAAAAMD8aI3QSTLG+LUkv9a9HwAAAAAA5k/36TgAAAAAANjFRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAEAbERoAAAAAgDYiNAAAAAAAbURoAAAAAADaiNAAAAAAALQRoQEAAAAAaCNCAwAAAADQRoQGAAAAAKCNCA0AAAAAQBsRGgAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAEAbERoAAAAAgDYiNAAAAAAAbURoAAAAAADaiNAAAAAAALRpi9BVdbSqPlZVv1NVd1XV/q59AQAAAAAwnzqPhH5vkq8fYzwvyf9IclvjvgAAAAAAmENtEXqM8RtjjC9ML34gybVd+wIAAAAAYD7t1Dmh/3aS/7DRFVV1pKpWq2r19OnTOzQOAAAAAAA7Ye92Prmq7kly9QZX3T7GeNf0Nrcn+UKSX9noPsYYdyS5I0kmk8nYzjwAAAAAAMyXbUXoMcZNF7u+ql6b5GVJXjLGEJgBAAAAAHaZbUXoi6mqm5P8gyTfOsb4XNd+AAAAAACYX53nhP6ZJF+Z5L1V9eGq+leN+wIAAAAAYA61HQk9xnhm130DAAAAALAYOo+EBgAAAABglxOhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAEAbERoAAAAAgDYiNAAAAAAAbURoAAAAAADaiNAAAAAAALQRoQEAAAAAaCNCAwAAAADQRoQGAAAAAKCNCA0AAAAAQBsRGgAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAEAbERoAAAAAgDYiNAAAAAAAbURoAAAAAADaiNAAAAAAALQRoQEAAAAAaNMeoavqR6pqVNVV3fsCAAAAAGC+tEboqnpakm9P8oed+wEAAAAAYD51Hwn95iQ/mmQ07wcAAAAAgDnUFqGr6juTnBxj/HbXPgAAAAAAmG97t/PJVXVPkqs3uOr2JD+W5KWXcR9HkhxJkoMHD25nHAAAAAAA5kyNceXPlFFVz03yviSfm266NsmpJC8YY/zxZp83mUzG6urqFZ8HAAAAAIArp6qOjzEml3PbbR0JvZkxxn1JnrpuoE8kmYwxPtWxPwAAAAAA5lP3GxMCAAAAALCLtRwJfaExxnU7sR8AAAAAAOaLI6EBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAEAbERoAAAAAgDYiNAAAAAAAbURoAAAAAADaiNAAAAAAALQRoQEAAAAAaCNCAwAAAADQRoQGAAAAAKCNCA0AAAAAQBsRGgAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAEAbERoAAAAAgDYiNAAAAAAAbURoAAAAAADaiNAAAAAAALQRoQEAAAAAaCNCAwAAAADQRoQGAAAAAKCNCA0AAAAAQBsRGgAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoE1rhK6qv1tVJ6rq/qr6yc59AQAAAAAwf/Z23XFVvTjJy5M8b4zxcFU9tWtfAAAAAADMp84joX8gyT8bYzycJGOMhxr3BQAAAADAHOqM0M9O8ler6oNV9Z+q6ps2ulFVHamq1apaPX36dOM4AAAAAADstG2djqOq7kly9QZX3T697ycleWGSb0ry9qp6xhhjrL/hGOOOJHckyWQyGRfeEQAAAAAAi2tbEXqMcdNm11XVDyS5cxqdP1RVX0xyVRKHOwMAAAAA7BKdp+O4O8mNSVJVz07yuCSfatwfAAAAAABzZltHQl/CW5O8tao+kuTzSV574ak4AAAAAABYbm0Reozx+SSv6bp/AAAAAADmX+fpOAAAAAAA2OVEaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAECbvbMeAAB2o7vvPZmjx07k1JmzuWb/Sm49fCi33HBg1mNdEecf28kzZ7OnKufGyIEle4w7YZm/R4Dl4zkL4LHx/MluIUIDwA67+96Tue3O+3L2kXNJkpNnzua2O+9LkoV/wXnhYzs3RpLleow7YZm/R4Dl4zkL4LHx/Mlu4nQcALDDjh478egLzfPOPnIuR4+dmNFEV85Gj+28ZXmMO2GZv0eA5eM5C+Cx8fzJbiJCA8AOO3Xm7Ja2L5JLPYZleIw7YZm/R4Dl4zkL4LHx/MluIkIDwA67Zv/KlrYvkks9hmV4jDthmb9HgOXjOQvgsfH8yW4iQgPADrv18KGs7NvzZdtW9u3JrYcPzWiiK2ejx3besjzGnbDM3yPA8vGcBfDYeP5kN/HGhACww86/ycgyvgv2+sd28szZ7KnKuTFyYIke405Y5u8RYPl4zgJ4bDx/spvUmL5r/TyYTCZjdXV11mMAAAAAAHARVXV8jDG5nNs6HQcAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAEAbERoAAAAAgDYiNAAAAAAAbURoAAAAAADaiNAAAAAAALQRoQEAAAAAaCNCAwAAAADQRoQGAAAAAKCNCA0AAAAAQBsRGgAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0aYvQVXV9VX2gqj5cVatV9YKufQEAAAAAMJ86j4T+ySQ/Psa4Psk/ml4GAAAAAGAX6YzQI8kTpx9/VZJTjfsCAAAAAGAO7W287x9Ocqyq/nnWYvdfbtwXAAAAAABzaFsRuqruSXL1BlfdnuQlSf7eGOOdVfU3k7wlyU0b3MeRJEeS5ODBg9sZBwAAAACAOVNjjJ47rvpskv1jjFFVleSzY4wnXuxzJpPJWF1dbZkHAAAAAIAro6qOjzEml3PbznNCn0ryrdOPb0zye437AgAAAABgDnWeE/rvJPnpqtqb5P9lesoNAAAAAAB2j7YIPcb4r0m+sev+AQAAAACYf52n4wAAAAAAYJcToQEAAAAAaCNCAwAAAADQRoQGAAAAAKCNCA0AAAAAQBsRGgAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAEAbERoAAAAAgDYiNAAAAAAAbURoAAAAAADaiNAAAAAAALQRoQEAAAAAaCNCAwAAAADQRoQGAAAAAKCNCA0AAAAAQBsRGgAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0GZbEbqqXllV91fVF6tqcsF1t1XVA1V1oqoOb29MAAAAAAAW0d5tfv5Hkrwiyc+v31hVz0nyqiRfl+SaJPdU1bPHGOe2uT8AAAAAABbIto6EHmN8dIxxYoOrXp7kbWOMh8cY/zPJA0lesJ19AQAAAACweLrOCX0gySfXXX5wug0AAAAAgF3kkqfjqKp7kly9wVW3jzHetdmnbbBtbHL/R5IcSZKDBw9eahwAAAAAABbIJSP0GOOmx3C/DyZ52rrL1yY5tcn935HkjiSZTCYbhmoAAAAAABZT1+k43p3kVVX1+Kp6epJnJflQ074AAAAAAJhT24rQVfVdVfVgkhcleU9VHUuSMcb9Sd6e5HeT/HqS140xzm13WAAAAAAAFsslT8dxMWOMu5Lctcl1b0zyxu3cPwAAAAAAi63rdBwAAAAAACBCAwAAAADQR4QGAAAAAKCNCA0AAAAAQBsRGgAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAEAbERoAAAAAgDYiNAAAAAAAbURoAAAAAADaiNAAAAAAALQRoQEAAAAAaCNCAwAAAADQRoQGAAAAAKCNCA0AAAAAQBsRGgAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgzbYidFW9sqrur6ovVtVk3fZvr6rjVXXf9M8btz8qAAAAAACLZu82P/8jSV6R5Ocv2P6pJH9jjHGqqr4+ybEkB7a5LwAAAAAAFsy2IvQY46NJUlUXbr933cX7kzyhqh4/xnh4O/sDAAAAAGCx7MQ5ob87yb2bBeiqOlJVq1W1evr06R0YBwAAAACAnXLJI6Gr6p4kV29w1e1jjHdd4nO/LslPJHnpZrcZY9yR5I4kmUwm41LzAAAAAACwOC4ZoccYNz2WO66qa5PcleR7xxi//1juAwAAAACAxdZyOo6q2p/kPUluG2P8t459AAAAAAAw/7YVoavqu6rqwSQvSvKeqjo2veoHkzwzyT+sqg9P/3vqNmcFAAAAAGDBXPJ0HBczxrgra6fcuHD7G5K8YTv3DQAAAADA4ms5HQcAAAAAACQiNAAAAAAAjURoAAAAAADaiNAAAAAAALQRoQEAAAAAaCNCAwAAAADQRoQGAAAAAKCNCA0AAAAAQBsRGgAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAECbvbMeAAAAAPiSu+89maPHTuTUmbO5Zv9Kbj18KLfccGDWYwGXwfqFjYnQAAAAMCfuvvdkbrvzvpx95FyS5OSZs7ntzvuSRMiCOWf9wuacjgMAAADmxNFjJx4NWOedfeRcjh47MaOJgMtl/cLmRGgAAACYE6fOnN3SdmB+WL+wOREaAAAA5sQ1+1e2tB2YH9YvbE6EBgAAgDlx6+FDWdm358u2rezbk1sPH5rRRMDlsn5hc96YEAAAAObE+TcvO3rsRE6dOZtr9q/k1sOHvKkZLADrFzZXY4xZz/CoyWQyVldXZz0GAAAAAAAXUVXHxxiTy7mt03EAAAAAANBGhAYAAAAAoI0IDQAAAABAGxEaAAAAAIA2IjQAAAAAAG1EaAAAAAAA2ojQAAAAAAC0EaEBAAAAAGgjQgMAAAAA0EaEBgAAAACgjQgNAAAAAEAbERoAAAAAgDYiNAAAAAAAbWqMMesZHlVVp5P8waznmKGrknxq1kPAArFm4PJZL7A11gxsjTUDW2PNwNZYM/PpL44xnnI5N5yrCL3bVdXqGGMy6zlgUVgzcPmsF9gaawa2xpqBrbFmYGusmcXndBwAAAAAALQRoQEAAAAAaCNCz5c7Zj0ALBhrBi6f9QJbY83A1lgzsDXWDGyNNbPgnBMaAAAAAIA2joQGAAAAAKCNCD0HqurmqjpRVQ9U1etnPQ/Mg6p6a1U9VFUfWbftq6vqvVX1e9M/nzTdXlX1L6dr6Heq6vmzmxxmo6qeVlXvr6qPVtX9VfVD0+3WDWygqp5QVR+qqt+erpkfn25/elV9cLpm/l1VPW66/fHTyw9Mr79ulvPDLFTVnqq6t6r+/fSy9QKbqKpPVNV9VfXhqlqdbvO6DDZRVfur6h1V9bHpv2leZM0sFxF6xqpqT5KfTfIdSZ6T5NVV9ZzZTgVz4d8kufmCba9P8r4xxrOSvG96OVlbP8+a/nckyc/t0IwwT76Q5O+PMb42yQuTvG7688S6gY09nOTGMcY3JLk+yc1V9cIkP5HkzdM185kk3z+9/fcn+cwY45lJ3jy9Hew2P5Tko+suWy9wcS8eY1w/xphML3tdBpv76SS/Psb4miTfkLWfN9bMEhGhZ+8FSR4YY3x8jPH5JG9L8vIZzwQzN8b4z0k+fcHmlyf5xenHv5jklnXbf2ms+UCS/VX1F3ZmUpgPY4w/GmP89+nH/ztrL9oOxLqBDU2/9//P9OK+6X8jyY1J3jHdfuGaOb+W3pHkJVVVOzQuzFxVXZvkryf5henlivUCW+V1GWygqp6Y5FuSvCVJxhifH2OciTWzVETo2TuQ5JPrLj843Qb8aX9+jPFHyVpwS/LU6XbrCNaZ/trzDUk+GOsGNjU9tcCHkzyU5L1Jfj/JmTHGF6Y3Wb8uHl0z0+s/m+TJOzsxzNS/SPKjSb44vfzkWC9wMSPJb1TV8ao6Mt3mdRls7BlJTif519PTPv1CVX1FrJmlIkLP3kZHBIwdnwIWm3UEU1X155K8M8kPjzH+18VuusE264ZdZYxxboxxfZJrs/bbaV+70c2mf1oz7FpV9bIkD40xjq/fvMFNrRf4km8eYzw/a6cNeF1VfctFbmvNsNvtTfL8JD83xrghyf/Nl069sRFrZgGJ0LP3YJKnrbt8bZJTM5oF5t2fnP8Vm+mfD023W0eQpKr2ZS1A/8oY487pZusGLmH6657/MWvnU99fVXunV61fF4+umen1X5U/fdooWFbfnOQ7q+oTWTt94I1ZOzLaeoFNjDFOTf98KMldWfufnV6XwcYeTPLgGOOD08vvyFqUtmaWiAg9e7+V5FnTd5Z+XJJXJXn3jGeCefXuJK+dfvzaJO9at/17p++Q+8Iknz3/KzuwW0zPtfmWJB8dY/zUuqusG9hAVT2lqvZPP15JclPWzqX+/iTfM73ZhWvm/Fr6niS/OcZwxA27whjjtjHGtWOM67L275XfHGP8rVgvsKGq+oqq+srzHyd5aZKPxOsy2NAY44+TfLKqDk03vSTJ78aaWSrltcDsVdVfy9qRBHuSvHWM8cYZjwQzV1W/muTbklyV5E+S/OMkdyd5e5KDSf4wySvHGJ+exrefSXJzks8l+b4xxuos5oZZqaq/kuS/JLkvXzpf549l7bzQ1g1coKqel7U3uNmTtQMz3j7G+KdV9YysHen51UnuTfKaMcbDVfWEJL+ctfOtfzrJq8YYH5/N9DA7VfVtSX5kjPEy6wU2Nl0bd00v7k3yb8cYb6yqJ8frMthQVV2ftTe/fVySjyf5vkxfo8WaWQoiNAAAAAAAbZyOAwAAAACANiI0AAAAAABtRGgAAAAAANqI0AAAAAAAtBGhAQAAAABoI0IDAAAAANBGhAYAAAAAoI0IDQAAAABAm/8PN0Ys8T00jRYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1800x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train['f8'].value_counts())\n",
    "plt.figure(figsize=(25,7))\n",
    "plt.scatter(range(620),train['f8'][:620])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=620, step=1)"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=train.grade\n",
    "train.drop(columns=['grade'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715355    182\n",
      "1.514653     57\n",
      "0.257144     17\n",
      "1.359619     12\n",
      "1.184463      8\n",
      "0.978439      5\n",
      "Name: f0, dtype: int64 0.641762    70\n",
      "1.441557    29\n",
      "1.115784     8\n",
      "1.289004     7\n",
      "0.910174     5\n",
      "Name: f0, dtype: int64\n",
      "1.951770    14\n",
      "2.133090    12\n",
      "1.751782    11\n",
      "0.424439     7\n",
      "0.572959     3\n",
      "0.178930     2\n",
      "0.690228     2\n",
      "2.218198     1\n",
      "Name: f1, dtype: int64 1.685194    6\n",
      "1.879301    5\n",
      "0.376165    4\n",
      "2.137664    4\n",
      "2.055155    3\n",
      "0.055869    2\n",
      "Name: f1, dtype: int64\n",
      "1.178239    38\n",
      "1.741378    22\n",
      "1.262444    20\n",
      "1.415911    19\n",
      "1.554297    12\n",
      "1.681332     5\n",
      "Name: f2, dtype: int64 1.129859    16\n",
      "1.213897    14\n",
      "1.688879    12\n",
      "1.366558     7\n",
      "1.503800     7\n",
      "Name: f2, dtype: int64\n",
      "0.639844    531\n",
      "Name: f3, dtype: int64 0.680634    219\n",
      "Name: f3, dtype: int64\n",
      "1.142565    207\n",
      "Name: f4, dtype: int64 1.12597    94\n",
      "Name: f4, dtype: int64\n",
      "1.981500    13\n",
      "1.526237    12\n",
      "1.632666     9\n",
      "2.183310     8\n",
      "1.756658     3\n",
      "1.498449     1\n",
      "2.367982     1\n",
      "Name: f5, dtype: int64 1.661231    7\n",
      "2.144754    4\n",
      "2.359774    3\n",
      "1.631819    1\n",
      "1.905623    1\n",
      "Name: f5, dtype: int64\n",
      "0.609069    545\n",
      "Name: f6, dtype: int64 0.591442    237\n",
      "Name: f6, dtype: int64\n",
      "0.300278    615\n",
      "Name: f7, dtype: int64 0.351512    262\n",
      "Name: f7, dtype: int64\n",
      "0.32857    612\n",
      "Name: f8, dtype: int64 0.408406    258\n",
      "Name: f8, dtype: int64\n",
      "0.0    620\n",
      "Name: f9, dtype: int64 0.24785    265\n",
      "Name: f9, dtype: int64\n",
      "0.629185    536\n",
      "Name: f10, dtype: int64 0.667229    222\n",
      "Name: f10, dtype: int64\n",
      "0.555769    566\n",
      "Name: f11, dtype: int64 0.52664    247\n",
      "Name: f11, dtype: int64\n",
      "0.740691    468\n",
      "Name: f12, dtype: int64 0.716754    207\n",
      "Name: f12, dtype: int64\n",
      "0.687096    507\n",
      "Name: f13, dtype: int64 0.62899    230\n",
      "Name: f13, dtype: int64\n",
      "0.415833    602\n",
      "Name: f14, dtype: int64 0.419631    258\n",
      "Name: f14, dtype: int64\n",
      "0.31441    614\n",
      "Name: f15, dtype: int64 0.24785    265\n",
      "Name: f15, dtype: int64\n",
      "0.555769    566\n",
      "Name: f16, dtype: int64 0.533978    246\n",
      "Name: f16, dtype: int64\n",
      "0.200483    619\n",
      "Name: f17, dtype: int64 0.24785    265\n",
      "Name: f17, dtype: int64\n",
      "0.427287    600\n",
      "Name: f18, dtype: int64 0.44457    256\n",
      "Name: f18, dtype: int64\n",
      "0.292413    615\n",
      "Name: f19, dtype: int64 0.24785    265\n",
      "Name: f19, dtype: int64\n",
      "0.482996    588\n",
      "Name: f20, dtype: int64 0.52664    247\n",
      "Name: f20, dtype: int64\n",
      "0.961955    334\n",
      "Name: f21, dtype: int64 0.941347    149\n",
      "Name: f21, dtype: int64\n",
      "0.665776    67\n",
      "1.499469    42\n",
      "0.664928    20\n",
      "0.945804    15\n",
      "1.775100    11\n",
      "0.666622     7\n",
      "0.574835     6\n",
      "1.207747     6\n",
      "1.110410     6\n",
      "1.499845     6\n",
      "1.340988     3\n",
      "1.058389     3\n",
      "0.465280     2\n",
      "0.321968     2\n",
      "1.208214     2\n",
      "0.323715     2\n",
      "1.608376     2\n",
      "1.536629     1\n",
      "1.422239     1\n",
      "0.466490     1\n",
      "0.884151     1\n",
      "1.340567     1\n",
      "Name: f22, dtype: int64 0.710140    20\n",
      "1.552467    16\n",
      "0.709301    14\n",
      "0.166840    12\n",
      "1.255525     8\n",
      "0.710978     4\n",
      "1.833871     3\n",
      "1.552851     3\n",
      "0.990335     3\n",
      "1.391000     2\n",
      "1.104081     2\n",
      "1.663581     1\n",
      "1.156767     1\n",
      "0.515817     1\n",
      "0.620631     1\n",
      "0.170372     1\n",
      "Name: f22, dtype: int64\n",
      "1.154141    106\n",
      "1.042703     32\n",
      "1.132731     20\n",
      "0.551210     18\n",
      "1.077346      9\n",
      "1.331429      7\n",
      "1.354218      6\n",
      "1.105274      4\n",
      "1.105385      4\n",
      "0.876912      4\n",
      "0.740705      3\n",
      "0.819176      3\n",
      "0.682208      2\n",
      "0.370292      2\n",
      "0.682388      2\n",
      "0.931074      1\n",
      "0.937625      1\n",
      "0.583780      1\n",
      "1.154247      1\n",
      "1.143486      1\n",
      "0.890761      1\n",
      "0.363957      1\n",
      "1.019074      1\n",
      "Name: f23, dtype: int64 1.162763    43\n",
      "1.049013    17\n",
      "1.140921    10\n",
      "0.543453     9\n",
      "1.084392     5\n",
      "0.739548     4\n",
      "1.162871     2\n",
      "1.024749     2\n",
      "1.343458     2\n",
      "0.577131     1\n",
      "0.543685     1\n",
      "0.820199     1\n",
      "0.345295     1\n",
      "1.112902     1\n",
      "1.366666     1\n",
      "1.113015     1\n",
      "0.934878     1\n",
      "Name: f23, dtype: int64\n",
      "1.370320    112\n",
      "1.226590     27\n",
      "0.943103      6\n",
      "1.215828      1\n",
      "Name: f24, dtype: int64 1.420852    45\n",
      "1.276194     7\n",
      "0.992850     3\n",
      "0.087368     2\n",
      "Name: f24, dtype: int64\n",
      "0.521427    572\n",
      "Name: f25, dtype: int64 0.479289    251\n",
      "Name: f25, dtype: int64\n",
      "2.125831    22\n",
      "1.930600    10\n",
      "Name: f26, dtype: int64 2.159458    11\n",
      "1.962107     1\n",
      "Name: f26, dtype: int64\n",
      "0.319576    613\n",
      "Name: f27, dtype: int64 0.295023    264\n",
      "Name: f27, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in train.columns:\n",
    "    print(train[i].value_counts(), test[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    620\n",
       "Name: f9, dtype: int64"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.f9.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.292413    615\n",
       "Name: f19, dtype: int64"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.f19.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24785    265\n",
       "Name: f19, dtype: int64"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.f19.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "## f17, f15, f9,f16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['f9'],inplace=True)\n",
    "test.drop(columns=['f9'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.414214    472\n",
       "1.000000     68\n",
       "1.732051     47\n",
       "2.000000     27\n",
       "0.000000      6\n",
       "Name: grade, dtype: int64"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_pred,y_true, eps = 1e-15):\n",
    "    y_pred = np.clip(y_pred,eps,1-eps)\n",
    "    return (-(y_true * np.log(y_pred)).sum(axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=list()\n",
    "l=[DecisionTreeClassifier(random_state=50),RandomForestClassifier(random_state=50),SVC(probability=True),AdaBoostClassifier(random_state=50),GradientBoostingClassifier(random_state=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mE:\\New folder\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \"\"\"\n\u001b[1;32m--> 493\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\New folder\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mE:\\New folder\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\New folder\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "sss=StratifiedShuffleSplit(random_state=150,test_size=0.2,n_splits=3)\n",
    "for m in l:\n",
    "    a = list()\n",
    "    for tr_index, te_index in sss.split(train,label):\n",
    "        xtrain, xtest = train.loc[tr_index,:], train.loc[te_index,:]\n",
    "        ytrain, ytest = label[tr_index], label[te_index]\n",
    "           \n",
    "        OneVsOneClassifier(m).fit(xtrain,ytrain)\n",
    "        p = m.predict_proba(xtest)\n",
    "        a.append(loss(p,pd.get_dummies(ytest).values))\n",
    "    print(np.mean(a))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    472\n",
       "1.0     68\n",
       "3.0     47\n",
       "4.0     27\n",
       "0.0      6\n",
       "Name: grade, dtype: int64"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.DataFrame(m.predict_proba(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_excel('Submit.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
